[    
    { 
        "question": "Organization number",
        "category":"1",
        "type": "number",
        "id": "1",
        "linked":"",
        "linkActivation":["0","0","0"],
        "risk":[],
        "stamp":"0",
        "readmore":"This number identifies the organization responsible for developing or operating the AI system. It ensures traceability and accountability, which are key principles in the AI Act and GDPR regulations."
    },
    { 
        "question": "Organization name",
        "category":"1",
        "type": "text",
        "text":"org",
        "id": "2",
        "linked":"",
        "linkActivation":["0","0","0"],
        "risk":[],
        "stamp":"0",
        "readmore":"The organization’s name is important for compliance with transparency regulations, ensuring that all stakeholders know who is responsible for the AI system."

    },
    { 
        "question": "Name of AI system",
        "category":"1",
        "type": "text",
        "text":"AI",
        "id": "3",
        "linked":"",
        "linkActivation":["0","0","0"],
        "risk":[],
        "stamp":"0",
        "readmore":"The name should clearly indicate the AI system to ensure traceability and facilitate audits or reviews required by the AI Act."
    },
    
    { 
        "question": "URL to were you save information about the AI-system",
        "category":"1",
        "type": "text",
        "text":"url",
        "id": "4",
        "linked":"",
        "linkActivation":[""],
        "risk":[],
        "stamp":"0",
        "readmore":"Transparency is a fundamental requirement under the AI Act, ensuring that users and affected individuals understand the system’s capabilities, limitations, and decision-making processes."
    },
    {
        "question": "Select AI System",
        "category":"1",
        "type": "dropdown",
        "id": "5",
        "linked":"",
        "linkActivation":["0","0","0"],
        "risk":[],
        "stamp":"1",
        "readmore":" The AI system type determines its risk category under the AI Act, which classifies AI into risk levels (e.g., minimal, limited, high). High-risk systems (e.g., biometric or employment-related systems) face stricter requirements.",
        "options": ["Question Answering Models",
        "Image Recognition Models",
        "Natural Language Processing",
        "Sentiment Analysis Models",
        "Image Generation Models",
        "Speech recognition Modedls",
        "Reinforcement Learning Models",
        "Generative Adversarial Networks",
        "Machine Translation Models",
        "Object Detection Models",
        "None of the above"]
    },
    {
        "question": "Which Groups will be affected by the AI system?",
        "category":"1",
        "type": "multi",
        "id": "6",
        "linked":"6A",
        "linkActivation":["0","1","1","1","1","1","0","0","1","0","0","1","0","0","1","0"],
        "risk":[],
        "stamp":"1",
        "readmore":"Identifying affected groups ensures the system complies with ethical principles of fairness and non-discrimination, outlined in the AI Act, especially for high-risk applications like healthcare, education, or law enforcement.",
        "options": ["The general public",
        "Children and young people (under 18)",
        "Elderly persons (65+)",
        "People with disabilities",
        "Ethnic minorities",
        "Low-income individuals",
        "Public sector (e.g., municipality, authority)",
        "Private sector (companies)",
        "Sensitive professional groups (e.g., healthcare staff, teachers)",
        "Law enforcement authorities",
        "Employees within the organization",
        "Students or pupils",
        "Individuals seeking jobs",
        "Individuals applying for housing or social services",
        "Individuals in migration management",
        "No specific groups"]
    },
    {
        "question": "Is the AI system used to manipulate the target group?",
        "category":"1",
        "type": "boolean",
        "id": "6A",
        "linkActivation":["0","0"],
        "risk":[["u",1]],
        "stamp":"0",
        "linked":"",
        "readmore":"Manipulating target groups may involve deceptive practices, violating transparency and fairness obligations under the AI Act. Such practices may be subject to strict regulations, particularly in high-risk applications.",
        "options": []
    },
    {
        "question": "Will individuals and businesses be informed about how the AI system works? ",
        "category":"2",
        "type": "boolean",
        "id": "7",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[],
        "stamp":"0",
        "readmore":"Transparency is a fundamental requirement under the AI Act, ensuring that users and affected individuals understand the system’s decision-making processes, capabilities, and limitations.",
        "options": []
    },
    {
        "question": "Is it legally established that you can use the data you want to use when developing, training, or using your AI system?",
        "category":"2",
        "type": "boolean",
        "id": "8",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[],
        "stamp":"1",
        "readmore":"Data usage must comply with GDPR and the AI Act, ensuring lawful use of personal data with explicit consent. This is especially important for high-risk systems.",
        "options": []
    },
    {
        "question": "Do you process sensitive personal data when developing, training, or using your AI system?",
        "category":"2",
        "type": "boolean",
        "id": "9",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[["H",1]],
        "stamp":"1",
        "readmore":"Processing sensitive data (e.g., racial or health data) requires strict safeguards under the GDPR and AI Act, including impact assessments and user consent.",
        "options": []
    },
    {
        "question": "Have you conducted a risk analysis regarding the risk of discrimination under the Discrimination Act, of those individuals who will develop, train, and evaluate the AI system?",
        "category":"2",
        "type": "Boolean",
        "id": "10",
        "backgroundColor": "lightyellow",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[],
        "stamp":"0",
        "readmore":"AI systems should be evaluated for potential bias and discrimination, as mandated by both the AI Act and national discrimination laws, ensuring fairness for vulnerable or marginalized groups.",
        "options": []
    },
    {
        "question": "Does the AI system involve social scoring (ranking of individuals based on their behavior, characteristics, or traits)?",
        "category":"2",
        "type": "Boolean",
        "id": "11",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[["u",1]],
        "stamp":"1",
        "readmore":"Social scoring, ranking individuals based on behavior or traits, is highly regulated or prohibited under the AI Act, particularly if it leads to unfair treatment or discrimination.",
        "options": []
    },
    {
        "question": "Does the AI system use biometric identification (e.g.facial recognition) in public spaces for real-time monitoring?",
        "category":"2",
        "type": "Boolean",
        "id": "12",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[["u",1]],
        "stamp":"1",
        "readmore":"Biometric identification, especially in public spaces, is considered high-risk under the AI Act and may require special permission",
        "options": []
    },
    {
        "question": "The AI system is used in: ",
        "category":"2",
        "type": "dropdown",
        "id": "13",
        "linked":"",
        "linkActivation":["0","0","0","0","0"],
        "risk":[["H",0], ["H",3], ["H",4]],
        "stamp":"0",
        "readmore":"The sector where the AI system is used determines its risk category. Critical infrastructure, law enforcement, or educational applications are high-risk and face stringent oversight under the AI Act.",
        "options": ["Critical infrastructure (e.g., energy, water supply) where a failure could jeopardize life or health",
        "Educational or vocational training programs that affect access to education or job opportunities",
        " Labor market, personnel management or to determine access to essential services (e.g., bank, housing)",
        " Law enforcement, the justice system, or migration management",
        "Healthcare",
        "None of the above"]
    },
    {
        "question": "Have you conducted an analysis of the AI system from an information security perspective?",
        "category":"3",
        "type": "Boolean",
        "id": "14",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[["HX",0]],
        "stamp":"0",
        "readmore":"Information security is essential for ensuring that AI systems do not expose users or data to unauthorized access. The AI Act mandates that high-risk systems implement robust security measures.",
        "options": []
    },
    {
        "question": "Have you clarified and documented other requirements that are placed for planning, documentation, measurements, testing, verification, and traceability for development and operation?",
        "category":"3",
        "type": "Boolean",
        "id": "15",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[["HX",0]],
        "stamp":"1",
        "readmore":"Thorough documentation of the AI system’s planning and testing is required under the AI Act, ensuring traceability and compliance, especially for high-risk systems.",
        "options": []
    },
    {
        "question":"Are there other components (or regulations) built into the IT system that interact with the AI system/model's results and affect the final outcome?",
        "category":"3",
        "type": "Boolean",
        "id": "16",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[],
        "stamp":"0",
        "readmore":"Understanding how other IT components influence AI results helps ensure the transparency and fairness mandated by the AI Act, especially in critical sectors like healthcare or employment.",
        "options": []
    },
    {
        "question": "Will the collected data be shared with third parties?",
        "category":"3",
        "type": "Boolean",
        "id": "17",
        "linked":"17A",
        "linkActivation":["1","0"],
        "risk":[],
        "stamp":"1",
        "readmore":"Data sharing with third parties must comply with GDPR and AI Act requirements, ensuring data is handled lawfully and transparently, especially when sensitive information is involved.",
        "options": []
    },
    {
        "question": "Can you ensure the data is not misused?",
        "category":"3",
        "type": "Boolean",
        "id": "17A",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[["HX",0]],
        "stamp":"0",
        "readmore":"",
        "options": []
    },
    {
        "question": "What is the availability of usable data like?",
        "category":"3",
        "type": "multi",
        "id": "18",
        "backgroundColor": "lightyellow",
        "linked":"",
        "linkActivation":["0","0","0"],
        "risk":[],
        "stamp":"0",
        "readmore":"Data availability and quality are crucial for the reliable functioning of AI systems. Under the AI Act, high-risk systems must ensure their data is up-to-date and representative to prevent biases.",
        "options": ["Data is continuously available and unrestricted",
        "Data is available but can only be used for a limited time (how long?)",
        "There is a risk that the content of the data source may change over time",
        "Data is not complete or representative for the task",
        "None of the above"]
    },
    {
        "question": "How is the data stored?",
        "category":"3",
        "type": "dropdown",
        "id": "19",
        "backgroundColor": "lightyellow",
        "linked":"19A",
        "linkActivation":["0","1","1","0","0"],
        "risk":[],
        "stamp":"0",
        "readmore":"Data storage methods must comply with GDPR and the AI Act, ensuring security, transparency, and protection against unauthorized access or data breaches.",
        "options": ["Own servers",
        "From third parties",
        "On the user's device",
        "We do not store any data",
        "None of the above"]
    },
    {
        "question": "Can you ensure the data is not misused?",
        "category":"3",
        "type": "Boolean",
        "id": "19A",
        "backgroundColor": "lightyellow",
        "linked":"",
        "linkActivation":["0","0","0"],
        "risk":[["HX",0]],
        "stamp":"0",
        "readmore":"By having continous and proper oversight of the data being shared, one can ensure a safe usage of vital information",
        "options": []
    },
    {
        "question": "What methods are used to protect data?",
        "category":"3",
        "type": "dropdown",
        "id": "20",
        "linked": "",
        "linkActivation":["0","0","0","0","0"],
        "risk":[["HX",4]],
        "stamp":"1",
        "readmore":"The AI Act and GDPR mandate robust data protection measures, including encryption and access control, particularly for high-risk systems handling sensitive data.",
        "options": [
            "Encryption during storage and transmission",
            "Access control and authorization management",
            "Anonymization or pseudonymization of sensitive data",
            "Regular security audits and monitoring",
            "No methods are used",
            "Method is not defined in the options available"
        ]
    },
    {
        "question": "Are there requirements for data to be deleted?",
        "category":"3",
        "type": "Boolean",
        "id": "21",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[],
        "stamp":"0",
        "readmore":"Data deletion must comply with GDPR principles such as data minimization and right to erasure, ensuring personal data is not retained longer than necessary.",
        "options": []
    },
    {
        "question": "Is there a risk that the data contains collection bias?",
        "category":"3",
        "type": "Boolean",
        "id": "22",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[],
        "stamp":"0",
        "readmore":"The AI Act encourages developers to assess and mitigate collection bias to prevent discrimination, ensuring that AI systems are fair and inclusive.",
        "options": []
    },
    {
        "question": "Is the AI system updated automatically via new data?",
        "category":"4",
        "type": "Boolean",
        "id": "23",
        "backgroundColor": "lightyellow",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[],
        "stamp":"0",
        "readmore":"Automated updates can enhance AI performance, but the AI Act requires that updates maintain system safety, transparency, and do not introduce new risks or biases.",
        "options": []
    },
    {
        "question": "Does the AI reporoduce the same results if given the exact same input?",
        "category":"4",
        "type": "dropdown",
        "id": "24",
        "backgroundColor": "lightyellow",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[],
        "stamp":"0",
        "readmore":"The AI Act encourages reproducibility to ensure reliability, especially in high-risk applications. Consistent results are critical for system validation and user trust.",
        "options": ["Yes", "No", "Not applicable"]
    },
    {
        "question": "How do you measure that the AI system is sufficiently trained?",
        "category":"4",
        "type": "multi",
        "id": "25",
        "backgroundColor": "lightyellow",
        "linked":"",
        "linkActivation":[],
        "risk":[],
        "stamp":"0",
        "readmore":"Proper training metrics ensure that AI systems perform reliably. The AI Act requires regular performance evaluations for high-risk systems, using established methods like confusion matrices.",
        "options": ["Confusion Matrix","Lift-curve","ROC-curve","Accuracy", "Precision", "Recall", "F1 score"]
    },
    {
        "question": "Are there results from system tests with users of the system?",
        "category":"4",
        "type": "Boolean",
        "id": "26",
        "linked":"",
        "linkActivation":["0","0","0"],
        "risk":[],
        "stamp":"0",
        "readmore":"User testing ensures that the AI system works as intended in real-world conditions. The AI Act encourages human oversight and validation of high-risk systems.",
        "options": []
    },
    {
        "question": "Is there a systematic way to ensure traceability, monitoring, and results for the AI system?",
        "category":"4",
        "type": "Boolean",
        "id": "27",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[["HX",0]],
        "stamp":"0",
        "readmore":"Traceability is key to compliance with the AI Act, ensuring that system operations and decisions can be audited, especially in high-risk contexts.",
        "options": []
    },
    {
        "question": "Are there any licenses associated with the AI systems or AI models included in the IT system?",
        "category":"4",
        "type": "Boolean",
        "id": "28",
        "linked":"",
        "linkActivation":["0","0"],
        "risk":[],
        "stamp":"0",
        "readmore":"Licensing ensures compliance with intellectual property and regulatory requirements, particularly for AI systems governed by the AI Act or similar frameworks.",
        "options": []
    },
    {
        "question": "Is there planning for how to act when the AI system does not function as it should?",
        "category":"4",
        "type": "Boolean",
        "id": "29",
        "linked":"",
        "linkActivation":[],
        "risk":[["HX",0]],
        "stamp":"1",
        "readmore":"Contingency plans are essential under the AI Act for high-risk systems, ensuring that malfunctions are handled without compromising user safety or rights.",
        "options": []
    },
    {
        "question": "Is the AI-system optimzed after initial training/test?",
        "category":"4",
        "type": "Boolean",
        "id": "30",
        "linked":"",
        "linkActivation":[],
        "risk":[],
        "stamp":"0",
        "readmore":"Continuous optimization after initial training or testing can improve the AI system's performance over time. However, the AI Act requires that such optimization does not introduce new risks or compromise the system’s transparency and accountability. High-risk systems should undergo rigorous validation and re-assessment to ensure they remain compliant with safety and fairness standards.",
        "options": []
    },
    {
        "question": "Does the model inform that users are interacting with an AI?",
        "category":"5",
        "type": "Boolean",
        "id": "31",
        "linked":"",
        "linkActivation":[],
        "risk":[["u",0]],
        "stamp":"1",
        "readmore":"Transparency about AI involvement is required by the AI Act, ensuring users know when they are interacting with automated systems, particularly in decision-making contexts.",
        "options": []
    },
    {
        "question": "Does the model inform that it's generated content (if it does generate) is made by an AI?",
        "category":"5",
        "type": "dropdown",
        "id": "32",
        "linked":"",
        "linkActivation":[],
        "risk":[["u",1]],
        "stamp":"1",
        "readmore":"Transparency about AI involvement is required by the AI Act, ensuring users know when they are interacting with automated systems, particularly in decision-making contexts.",
        "options": ["Yes, the user is informed", "No, the user is not informed", "Ai model does not generate content"]
    },
    {
        "question": "Is the AI system designed to give explanations for its decisions (explainability)?",
        "category":"5",
        "type": "Boolean",
        "id": "33",
        "linked":"",
        "linkActivation":[],
        "risk":[],
        "stamp":"0",
        "readmore":"Explainability is crucial for building trust and accountability in AI systems, particularly in high-risk areas like healthcare or law enforcement, as mandated by the AI Act",
        "options": []
    },
    {
        "question": "How will the AI system be used in decision-making?",
        "category":"5",
        "type": "dropdown",
        "id": "34",
        "linked":"34A",
        "linkActivation":["0","1","0"],
        "risk":[],
        "stamp":"1",
        "readmore":"The AI Act distinguishes between AI systems that support human decision-making and those that make autonomous decisions, with stricter regulations for the latter.",
        "options": [" To support a decision made by a human",
        "To independently make automated decisions",
        "None of the above"]
    },
    {
        "question": "Is there a documented process for informing users or affected individuals when AI is used in decision-making?",
        "category":"5",
        "type": "boolean",
        "id": "34A",
        "linked":"",
        "linkActivation":[],
        "risk":[["HX",0]],
        "stamp":"0",
        "readmore":"Transparency in AI-based decision-making is a core principle of the AI Act, ensuring that affected individuals understand how AI influences decisions.",
        "options": []
    },
    {
        "question": "Is the system subject to human oversight to intervene or override decisions?",
        "category":"5",
        "type": "boolean",
        "id": "35",
        "linked":"",
        "linkActivation":[],
        "risk":[["HX",0]],
        "stamp":"0",
        "readmore":"Human oversight is a key safeguard required by the AI Act, particularly for high-risk AI systems that may affect individuals’ rights or well-being.",
        "options": []
    }
]